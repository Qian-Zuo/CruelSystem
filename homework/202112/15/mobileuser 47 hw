Transaction processing vs analytic processing


Property	OLTP（transaction processing system）	OLAP（analytic system）
Main read pattern	Small number of records per query，by key	Aggregate over large number of records
Main write pattern	Random access, low latency	Bulk or stream
Use case	End uer/ web application	Internal analyst, decission support
What data represent 	Latest state of data	History of evetns
Data sie 	GB to TB	TB to PB

Reliable, scalable and maintainbale application


Most of application is data intensive in stead of compute-intensive

Data-intensive applicate:
	- Database
	- Remember the result of expensive(cache)
	- Search indexes
	- Stream procession
	- Batch processing



Fundamentals:
	- Reliability
			§ Systenm shoul work correctly even in the face of adversity(heardware, software, human fault).
			§ Performs function expected
			§ Tolerate mistakes
			§ Performance is good enough under expected load and data volume.
			§ Prevents unauthorized access and abuse.
		Hardware faults
			§ Usually solved by redundant resources + fault-tolerance techniques
		Software faults
			§ Test
			§ Process isolation
			§ Allow process to crash and restart
			§ Measure and monitoring
			§ Analyzing
		Human fault
	- Scalability
		○ System's ability to cope with increase load
		Load: 
			- QPS
			- Write/Read ratio
			- Simultaneously active users
			- Hit rate on a cache
			- Etc
		Describe performance
			- Increase load, keep system resource unchanged, see how it the performance.’
			- Increase load, how you increase the resource to keep the performance unchanged.
			- User percentile is good way to measure performance.
			- Outlier:离群值
			- Queue delays -> offen account for large part of the response time at high percentile.
		Approaches for cop with load
			- Vertical scaling (add resource to single node)
			- Horizontal scaling: add more machines
	- Maintainability
		○ Operability
			- Monitoring the health and quickly restore 
			- Tackling down the cause of problems
			- Keep software and platform up to date
			- Anticipating future problems
			- Establish good practice and tools for deployment and config and more
			- Performing complex maintenance tasks, such as move an application from one platform to another
			- Maintain the security of the system
			- Doc
		○ Simplicity
			- Abstraction
		○ Evolvability
			
			
		
	- Maintability 
		○ Should be easy to adapt the system to new use cases.
	


Data Model

Relational model:
	- Business data processing
	- Lay out all the data in table
	

NOSQL
	- Motivation
		○ Scalability (larger dataset or high write throughput)
		○ Specialized query operations
		○ Need more dynamic and expressive data model
	

Relational database vs Document database

	- Document database is schema flexible and beetter performance due to locality(no need to join)
	- Relational database is good at joins, n to n and n t one relationships

Which to use:
	- If your application has a document like structure, then -> document model
	- If need to join, probably -> relational database

Document model
Schema on read: similar to dynamic type checking in programming languages


Relational model
Schema on write: similar to static type checking in programing language

Data locality:
Reasonable locality could improve the performance. 

Convergence of document and relational databases

PostgreSQL, MySQL, DB2 supports json

Documents database: RethinkDB supports joins

Query Language:

SQL
	- Declarative language 
		○ Declarative language could lend themselves to execute in parallel
	
IMS, CODASYL
	- Query using imperative code


MapReduce query
	- Map and reduce functions are somewhat restricted in what they are allowed to do.
	- Functions must be pure functions. They can't perform additional database query.


Graph-Like Data Model

Many-to-Many relationships
	- Vertices - edges
	- Property graph model, triple-store model.

Query language:
	- Cypher, SPARQL, Datalog

Property Graph
	- Each vertex:
		○ Unique identitfier
		○ Outgoing edges
		○ Incoming edges
		○ A collections of properties
	- Each edge:
		○ Unique identifier
		○ Tail vertex
		○ Head vertex
		○ A label that describe the relationship
		○ A collection of properties
Create table Vertices {
Vertext_ID: Primary key,
Properties: Json
}

Create table edges {
	Edge_id: primary key,
	Tail_vertex: integer references vertices(vertex_id)
	Head_vertex integer reference vertices(vertex_id),
	Label text,
	Properties json,
}

Create index edges_tail on edge (tail_vertex)
Create index edges_heads on edges (head_vertex)

Important aspects:
	- An vertex can have an edge connecting it with any other vertex
	- Given a vertex, it's easy to find both its incoming and outgoing edges -> traverse the graph
	- Using different labels for different relationships

Pros:
	- Graph models could do the things that difficult for relational models. Such as, different country has different regional structures (France has departments and regions while US has counties and states).
	- Easy to evolve. Graph can easily to add the new nodes

Cypher Query Language:
	- Different data models are designed for different use case, even same query in one query could requires more queries in other.

Triple-Stores and SPARQL

Triple-store model is mostly the equivalent to the property graph model, but using different words to describe the same ideas.
Format: three-part statement: (subject, predicate, object) eg (Jim, likes, Bananas)
	- Subject is same to vertex in graph model
	- Object is one of two things:
		○ Properties eg, (lucy, age, 33) -> predicate(谓词） age is like property 
		○ Another vertex in graph, (lucy, married to, allen),  predicate is like a edge
	
	
 The SPARQL query language
Select ?personName where {
Person :name  ?personName
?person :BornIN  // :within*// :name "US".
?person :livesIN  //:within*// :name :Europe"
}


Graph database vs network model

	- Network model: it has schema restriction while graph database doesn't
	- Network model: the only way to access a particular record is to traverse one of the access path. 
		○ In graph datamodel, it can access vertex by its unique ID.
	- In network model, the children of a record are ordered set.
		○ In graph model, vertices and edges are not sorted
	- In network model, all queries are imperative.
		○ In both imperative code and declarative language work.


Summary:

Document database: use case where data comes in self-contained documents and relationships between on documents and another are rare
Graph database goes in the opposite direction, anything is related to everything.

Data model
	- Start schema
		○ Fact table
		○ Dimension tables
	- Snowflake schema


Column-oriented storage better for analytics (HDFS, Hive)
	- Fact table has hundreds of columns, only need 4-5 of them
	- OLTP uses row/doc/entity as continuous process, very inefficient in OLAP
	- Good for join, since don't need to load all rows only current columns' rows

Column compressins:
	- Bitmap encoding


Sort order
	- Sort by appending order
	- If sort sort all (since it's column oriented DB)
	
