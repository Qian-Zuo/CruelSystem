# 210511 Day0003 Page 11-13 of [MapReduce](https://pdos.csail.mit.edu/6.824/papers/mapreduce.pdf)

One major application of MapReduce is for Large-Scale Indexing. As in Google in 2004, more than 20 terabytes of webpage raw data are indexed with only 700 lines of MapReduce code, compared with 3800 lines of C++ for the same functionality. Moreover, since machine failures and network transmission is handled by MapReduce, the performance is increased and developer should be less distracted by these details.

There are many related works for MapReduce. Bulk Synchronous Programming and some MPI primitives provides more flexibility, while MapReduce provides transparent fault-tolerance. The backup task mechanism learns from the eager scheduling mechanism in Charlotte System, but as an improvement, skipping bad records instead of repeatedly trying is adopted. With a restricted programming model, MapReduce can easily partition the problem into fine-grained tasks, and make it easier to schedule redundant backup tasks with locality awareness.

A "Word Frequecy" program is provided in Appendix A. We can see that to use MapReduce, we only need to define our own mapper and reducers and register it. The rest is left to the library to inherit our customized classes and finish the work we expect. The mapper defines how we partition a document to words, while the reducer iterates over all entries and merges the word frequency. Tuning parameters including the number of machines, and the memory to be used can be customized and it makes MapReduce flexible.

The phylosophy we can learn from MapReduce is that restricting the model, optimally utilizing the scarce resources and scheduling redundant execution are great techniques for optimizing large-scale computational clusters.
