
2. Partitioning of Key-Value Data

	Goal: to spread the data and the query load evenly across nodes
	hot spot: A partition with disproportion‐ ately high load <-- to avoid
	
	1. Partitioning by Key Range
	   the partition bound‐ aries need to adapt to the data. we can keep keys in sorted order.
	   adv: Range scans are very useful in this case, because they let you easily fetch, say, all the readings from a particular month.
	   disadv: certain access patterns can lead to hot spots (solution: combine multiple indices, like timestamp + sensor name)

	2. Partitioning by Hash of Key
	   A good hash function takes skewed data and makes it uniformly distributed.
	   assign each partition a range of hashes\, and every key whose hash falls within a partition’s range will be stored in that partition. The partition boundaries can be evenly spaced, or they can be chosen pseudorandomly.
	   adv: good at distributing keys fairly among the partitions.
	   disadv: couldn't do efficient range queries (any range query has to be sent to all partitions)
	   * Cassandra achieves a compromise between the two partitioning strategies.

	3. Skewed Workloads and Relieving Hot Spots
	   couldn't avoided hot spots, e.g. celebrity cause a sorm of activity => a large volume of writes to the same key.
	   solution: to add a random number to the beginning or end of the key. (two-digit decimal random number) => split the writes to the key evenly across 100 different keys, allowing those keys to be distributed to different partitions
	   issue: any reads has to read the data from all 100 keys and combine it. Most keys with low write throughput this would be unnecessary overhead. Thus, also need to track which keys are being split. (so, a trade-off)

3. Partitioning and Secondary Indexes

	A secondary index usually is a way of searching for occurrences of a particular value.
	Secondary indexes are the main reason & goal of search servers such as Solr and Elasticsearch.
	issue: they don’t map neatly to partitions

	1. Partitioning Secondary Indexes by Document (local index)
	   Each partition is completely separate: each partition main‐ tains its own secondary indexes.
	   When write, only need to deal with the partition that contains the primary key that are written.
	   When read, need to send the query to all partitions, and combine all the results.
	   Widely used in Cassandra, Elasticsearch, etc.

	2. Partitioning Secondary Indexes by Term (global index)
	   A global index must also be partitioned, but it can be partitioned differently from the primary key index.
	   (partition could be by term itself, or hash. like the options of primary index)
	   Read is efficient. only needs to make a request to the partition containing the term that it wants.
	   But write is slower and complicated. (a write to a single document may now affect multiple partitions of the index)
	   In practice, updates to global secondary indexes are often asynchronous.

4. Rebalancing Partitions

	Defination: the process of moving load from one node in the cluster to another.
	Min requirements: 
	(1) fairly shared load
	(2) continue accepting reads and writes while rebalancing
	(3) only move necessary data (to be fast and to minimize the network and disk I/O load)
