## 210510 Day0001 Page 1-5 of [MapReduce](https://pdos.csail.mit.edu/6.824/papers/mapreduce.pdf)

After reading the first 5 pages, I learned about the history of MapReduce and have got an overview of the system. MapReduce inherits the word Map and Reduce from Lisp, which is a functional programming language. It is designed for parallel computing, especially for string processing. Map is for splitting the data, and Reduce is used for merging the result.

The MapReduce cluster consists of a master node and thousands of worker nodes. If there is a text file and a MapReduce task, the library firstly splits the data into M pieces of typically from 16 MB to 64 MB, making them M map tasks, and if the final result is R pieces, there are R reduce tasks. Each of (M + R) tasks are assigned to one node. Each map node will return their intermediate values and the Reduce function will sort and merge them to get the result.

The paper also includes fault tolerance. The master node pings its worker node periodically, if one of the nodes fails, the task will be assigned to other ones. But if the master node fails, the whole program wil be aborted.

In terms of data locality. Since Google's GFS stores data on each of the nodes and with 3 copies of each data and the nodes can also be used for computation, the master node takes the location information to make sure that computation is performed on the node data is located or on a node conntect to the same switch.